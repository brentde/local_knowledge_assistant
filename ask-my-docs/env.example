# Core
APP_ENV=development              # development | staging | production
PORT=8000

# OpenAI / LLM
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o-mini
EMBEDDING_MODEL=text-embedding-3-small

# Persistence / paths
CHROMA_PERSIST_DIR=/data/chroma
DATA_DIR=/data/uploads

# Service behavior
TOP_K_DEFAULT=4
MAX_CONTEXT_TOKENS=3000         # prompt/truncation tuning
LOG_LEVEL=info                  # debug | info | warning | error

# Optional toggles
USE_LOCAL_MODEL=false           # if you add Ollama/local LLM later
LOCAL_MODEL_URL=http://localhost:11434
RATE_LIMIT_PER_MINUTE=60
